{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe0236a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA COLUMNS ['analyzer_version', 'artist_7digitalid', 'artist_familiarity', 'artist_hotttnesss', 'artist_id', 'artist_latitude', 'artist_location', 'artist_longitude', 'artist_mbid', 'artist_name', 'artist_playmeid', 'genre', 'idx_artist_terms', 'idx_similar_artists', 'release', 'release_7digitalid', 'song_hotttnesss', 'song_id', 'title', 'track_7digitalid', 'analysis_sample_rate', 'audio_md5', 'danceability', 'duration', 'end_of_fade_in', 'energy', 'idx_bars_confidence', 'idx_bars_start', 'idx_beats_confidence', 'idx_beats_start', 'idx_sections_confidence', 'idx_sections_start', 'idx_segments_confidence', 'idx_segments_loudness_max', 'idx_segments_loudness_max_time', 'idx_segments_loudness_start', 'idx_segments_pitches', 'idx_segments_start', 'idx_segments_timbre', 'idx_tatums_confidence', 'idx_tatums_start', 'key', 'key_confidence', 'loudness', 'mode', 'mode_confidence', 'start_of_fade_out', 'tempo', 'time_signature', 'time_signature_confidence', 'track_id']\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "dataset_dir = \"../../MillionSongSubset\"\n",
    "csv_path = \"../../MillionSongSubsetCSV.csv\"\n",
    "\n",
    "# Define the relevant data columns\n",
    "schema_file = \"../../MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5\"\n",
    "data_columns = []\n",
    "with h5py.File(schema_file, 'r') as schema:\n",
    "    metadata_data = schema['metadata']['songs'][0]\n",
    "    analysis_data = schema['analysis']['songs'][0]\n",
    "    metadata_fields = metadata_data.dtype.fields.keys()\n",
    "    analysis_fields = analysis_data.dtype.fields.keys()\n",
    "    for key in metadata_fields:\n",
    "        data_columns.append(key)\n",
    "    \n",
    "    for key in analysis_fields:\n",
    "        data_columns.append(key)\n",
    "print('DATA COLUMNS', data_columns)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    # Write the header row with the column names\n",
    "    writer.writerow(data_columns)\n",
    "    \n",
    "    # Loop over all subdirectories in the first level\n",
    "    for sub_dir_1 in sorted(os.listdir(dataset_dir)):\n",
    "        # Ignore any non-directory entries\n",
    "        if not os.path.isdir(os.path.join(dataset_dir, sub_dir_1)):\n",
    "            continue\n",
    "            \n",
    "        # Loop over all subdirectories in the second level\n",
    "        for sub_dir_2 in sorted(os.listdir(os.path.join(dataset_dir, sub_dir_1))):\n",
    "            if not os.path.isdir(os.path.join(dataset_dir, sub_dir_1, sub_dir_2)):\n",
    "                continue\n",
    "                \n",
    "            # Loop over all subdirectories in the third level\n",
    "            for sub_dir_3 in sorted(os.listdir(os.path.join(dataset_dir, sub_dir_1, sub_dir_2))):\n",
    "                if not os.path.isdir(os.path.join(dataset_dir, sub_dir_1, sub_dir_2, sub_dir_3)):\n",
    "                    continue\n",
    "                    \n",
    "                # Use glob to find all the .h5 files in the fourth level\n",
    "                h5_files = glob.glob(os.path.join(dataset_dir, sub_dir_1, sub_dir_2, sub_dir_3, \"*.h5\"))\n",
    "                \n",
    "                # Loop over each .h5 file and write the data to the CSV file\n",
    "                for h5_file in h5_files:\n",
    "                    # Open the .h5 file\n",
    "                    row_data = []\n",
    "                    with h5py.File(h5_file, 'r') as f:\n",
    "                        # Get the relevant data\n",
    "                        metadata_data = f['metadata']['songs'][0]\n",
    "                        analysis_data = f['analysis']['songs'][0]\n",
    "                        metadata_fields = metadata_data.dtype.fields.keys()\n",
    "                        analysis_fields = analysis_data.dtype.fields.keys()\n",
    "                        \n",
    "                        for field in metadata_fields:\n",
    "                            try:\n",
    "                                row_data.append(metadata_data[field])\n",
    "                            except(ValueError):\n",
    "                                row_data.append(None)\n",
    "                            \n",
    "                        for field in analysis_fields:\n",
    "                            try:\n",
    "                                row_data.append(analysis_data[field])\n",
    "                            except(ValueError):\n",
    "                                row_data.append(None)\n",
    "                                                \n",
    "                        writer.writerow(row_data)\n",
    "\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64bcf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'ARV4KO21187FB38008', b'ARWHM281187FB3D381', b'ARJGOG11187B98D89F', b'AR9ODB41187FB459B2', b'ARXM6VQ1187FB5B1E0', b'ARNWZ1N1187B9B71BA', b'ARDWYZZ11F4C8413FA', b'ARTP3H51187B98FB75', b'ARWCDXN12454A4D1E8', b'ARJ54S61187B9ACD39', b'AR5PF241187B989C1D', b'ARR7MLL1187B99B636', b'ARLMHFV1187B9A3833', b'ARPRERY1187B99E2DC', b'AR34BCQ1187B9A68E4', b'ARFWBUC11F4C8413DA', b'ARPWGMN1187FB560E3', b'ARVCIVW12454A4D1E7', b'ARG89HY1187FB3CA15', b'AR9IGU51187FB40D6B', b'ARNNOYR11F4C845127', b'ARZMFNT11F4C8413DD', b'ARPR9W71187FB3723A', b'AR5VBGP1187B98EB43', b'ARFHDOI1187FB57230', b'ARBSQPF11F4C8413E0', b'AROYGID11F4C8413DB', b'ARDXUGZ11F4C84452F', b'ARMW4I01187B98AEF8', b'AR7AYQG1187B994B3F', b'ARHVZEM11F4C841FF9', b'ARP9H0U1187FB3FEA7', b'ARVSIGU11F4C8413E6', b'AROWKNS1187FB59ED5', b'ARUSTLW11F4C8413DE', b'ARSKPDX11F4C83D2A9', b'ARB4D891187B9954F7', b'ARRIWD31187B9A9B4A', b'ARNAAQH11F4C8413E1', b'ARVRVYO11F4C8413DF', b'ARNIZ5P1187B989AF5', b'AR6YR7H1187FB40D23', b'ARVAOCN12454A4CD5D', b'ARQN3MO1187B98A811', b'AR6M50Z1187B9A3503', b'ARYEBOD11F4C83CD89', b'ARQTORN11F50C4CED2', b'ARUGOBE1269FCD74CE', b'ARD3STO1187FB3E36A', b'ARXU8YQ1187B999861', b'AR0D3LM1187B9B9592', b'ARCTCBU11F4C8413DC', b'ARAVZPG1187B98F815', b'AR79GH61187B993492', b'ARBCGAP12086C13383', b'ARLQK3P1187FB42113', b'ARGNP1T1187FB5024D', b'ARDIP5S1187FB57056', b'ARWG53T1187FB44281', b'ARV7RUN1187B9AF59C', b'ARHAEF41187FB38ECB', b'AR6UET41187B98C8BE', b'ARYYFT91187FB50113', b'ARD1KGL1187B98C838', b'ARKBKTR1187FB39255', b'ARRPOUR1187FB4D0BA', b'AR6VXP71187FB5B898', b'ARRWZGD11F50C4EDAE', b'ARVCPYN11F4C83B19D', b'AROKSCN1269FCD6CF1', b'AR7YOK41187B9A3E0C', b'ARSVLBA11F50C5126C', b'ARGVYYD11C8A416342', b'ARSK1IB1187B996850', b'ARD39VZ1187B9B9A57', b'ARIPNAN1187FB3E577', b'ARK276D1187FB3D8FC', b'AROWLBR11F4C84790E', b'ARRX19M1187FB5756D', b'ARLERFY11F50C4ABF2', b'ARJ5PHW119B8668EB3', b'ARQIMRI11F4C845124', b'AR6S4EF1187B99A528', b'ARYSPOI11F4C847915', b'ARVFENS11F50C4ABE5', b'ARTH9041187FB43E1F', b'ARRZSQJ1269FB30A5F', b'ARWFREB1187B98B09D', b'ARZ3EIB1187B989D35', b'ARNHXXE11F4C84129E', b'ARACWVH1187FB55452', b'AR3QS2R1187B9953C7', b'ARTXGGI1187B9B3D58', b'AR92C2I1187FB4161C', b'ARNNCRQ11F50C4ABE7', b'ARQPFMZ1187B9B1504', b'ARPZEFW11F50C47E67', b'ARSIEKZ122ECCBC0B1', b'AR0WMTB1187B9A8E0F', b'ARHRRWZ11F4C846224']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(schema_file, 'r') as schema:\n",
    "    print(list(schema['metadata']['similar_artists']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c18cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
